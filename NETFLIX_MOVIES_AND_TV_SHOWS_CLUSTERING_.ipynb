{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sandeep81299/Netflix-Movies-and-TV-shows-Prediction/blob/main/NETFLIX_MOVIES_AND_TV_SHOWS_CLUSTERING_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Netflix Movies and TV show clustering\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1** -**Sandeep Salunke**\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The entertainment industry is highly competitive, and success is dependent on various factors, including genre, rating, production budget, cast, and more. In this context, a study was conducted to understand the factors influencing the popularity of movies and TV shows on Netflix. The study used a dataset containing around 12 variables to cluster the movies and TV shows based on their popularity and audience preferences.\n",
        "The first step in the analysis involved data wrangling, where missing values were handled, and unique values were checked. The study identified that there were 2389 missing values for the 'director' column, 718 for the 'cast' column, 507 for the 'country' column, and 10 for the 'date_added' column. These missing values were removed by dropping the corresponding rows.\n",
        "\n",
        "Next, the study performed exploratory data analysis (EDA). The number of movies on Netflix is greater than the number of TV shows, with 5372 movies and 2398 TV shows currently available on the platform. The most common rating for TV shows is TV-MA, indicating that a significant portion of the TV shows available on Netflix are intended for adult audiences. Additionally, TV-MA is the most common rating for both movies and TV shows, suggesting that Netflix's content caters to a primarily adult demographic, with a focus on mature and potentially controversial themes.\n",
        "The years 2017 and 2018 had the highest number of movie releases, while 2020 had the highest number of TV show releases. The growth rate of movie releases on Netflix is significantly faster than that of TV shows. Since 2015, there has been a substantial increase in the number of movies and TV show episodes available on Netflix. However, there has been a notable drop in the number of movies and TV show episodes produced after 2020. It appears that Netflix has given more attention to increasing its movie content rather than TV shows.\n",
        "\n",
        "According to the countplot, it appears that Netflix adds the highest number of movies and TV shows during the period between October and January. This period seems to be the busiest time of year for Netflix in terms of adding new content to its platform. Netflix has the highest number of content in the United States, followed by India. India has the highest number of movies on Netflix.\n",
        "\n",
        "To cluster the shows, the study focused on six key attributes: director, cast, country, genre, rating, and description. These attributes were transformed into a 10,000-feature TFIDF vectorization, and Principal Component Analysis (PCA) was used to reduce the components to 3000, capturing more than 80% of the variance.\n",
        "Next, two clustering algorithms, K-Means and Agglomerative clustering, were used to group the shows. K-Means determined that the optimal number of clusters was 5, while Agglomerative clustering suggested 7 clusters, which were visualized using a dendrogram.\n",
        "\n",
        "Finally, a content-based recommender system was created using the similarity matrix obtained through cosine similarity. This system provides personalized recommendations based on the type of show the user has watched, giving them 10 top-notch suggestions to explore.\n",
        "In summary, the study identified key trends in the Netflix dataset, including the growth rate of movies versus TV shows, the busiest period for adding new content, and the content demographics. Through clustering and a content-based recommender system, the study was able to provide personalized recommendations based on the user's viewing history. This study provides valuable insights into the factors influencing the popularity of movies and TV shows on Netflix, offering a foundation for further research and analysis.."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Sandeep81299/Netflix-Movies-and-TV-shows-Prediction"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This dataset consists of tv shows and movies available on Netflix as of 2019. The dataset is collected from Flixable which is a third-party Netflix search engine.**\n",
        "\n",
        "**In 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming service’s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. It will be interesting to explore what all other insights can be obtained from the same dataset.**\n",
        "\n",
        "**Integrating this dataset with other external datasets such as IMDB ratings, rotten tomatoes can also provide many interesting findings**\n",
        "\n",
        "**In this project, you are required to do**\n",
        "\n",
        "1.Exploratory Data Analysis.\n",
        "\n",
        "2.Understanding what type content is available in different countries.\n",
        "\n",
        "3.Is Netflix has increasingly focusing on TV rather than movies in recent years.\n",
        "\n",
        "4.Clustering similar content by matching text-based features."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import math\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "import missingno as msno\n",
        "\n",
        "# library used for Analyzing and Visualization purpose\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Word Cloud library\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "# library used for textual data prerocessing\n",
        "import string\n",
        "string.punctuation\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from scipy.stats import ttest_ind\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# library used for Clusters impelementation\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import scipy.cluster.hierarchy as shc\n",
        "\n",
        "# library used for building recommandation system\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Warnings library. Would help to throw away warnings caused.\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading CSV File\n",
        "df = pd.read_csv('/content/drive/MyDrive/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv')"
      ],
      "metadata": {
        "id": "dMYWGNM4PjKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "# count the number of duplicate rows in the DataFrame\n",
        "duplicate_rows = df[df.duplicated()]\n",
        "duplicate_count = len(duplicate_rows)\n",
        "\n",
        "# print the result\n",
        "print(\"Number of duplicate rows: \", duplicate_count)\n"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#total null values\n",
        "df.isnull().sum().sum()"
      ],
      "metadata": {
        "id": "jLA_j2avG2Yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "# visualize missing data with a heatmap\n",
        "msno.heatmap(df)\n",
        "plt.show()\n",
        "\n",
        "# visualize missing data with a bar chart\n",
        "msno.bar(df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Dataset contains 7787 rows and 12 columns.Their are four columns containing missing values.The Total 3631 missing values present in the table"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns\n",
        "     "
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**show_id** : Unique ID for every Movie / Tv Show\n",
        "\n",
        "**type** : Identifier - A Movie or TV Show\n",
        "\n",
        "**title** : Title of the Movie / Tv Show\n",
        "\n",
        "**director** : Director of the Movie\n",
        "\n",
        "**cast** : Actors involved in the movie / show\n",
        "\n",
        "**country** : Country where the movie / show was produced\n",
        "\n",
        "**date_added** : Date it was added on Netflix\n",
        "\n",
        "**release_year** : Actual Releaseyear of the movie / show\n",
        "\n",
        "**rating** : TV Rating of the movie / show\n",
        "\n",
        "**duration** : Total Duration - in minutes or number of seasons\n",
        "\n",
        "**listed_in** : Genere\n",
        "\n",
        "**description**: The Summary description"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "# iterate over each column in the DataFrame\n",
        "for col in df.columns:\n",
        "    # get the unique values for the column\n",
        "    unique_vals = df[col].unique()\n",
        "    # print the column name and its unique values\n",
        "    print(col, unique_vals)"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "#Handling Null Values\n",
        "df['cast'].fillna(value='No cast',inplace=True)\n",
        "df['country'].fillna(value=df['country'].mode()[0],inplace=True)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#'date_added' and 'rating' contains an insignificant portion of the data so we will drop them from the dataset\n",
        "df.dropna(subset=['date_added','rating'],inplace=True)"
      ],
      "metadata": {
        "id": "5q2U7fXAMbBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#again checking is there any null values are not\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "PeqHqMV2Mkdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filled the null values in 'cast' column with 'No cast'\n",
        "Filled the null values in 'country' column with the mode of the column\n",
        "Dropped rows with null values in 'date_added' and 'rating' columns\n",
        "Dropped 'director' column\n",
        "Checked if there are any remaining null values in the dataset\n",
        "Some possible insights that can be derived from this dataset after the manipulations are done include:\n",
        "\n",
        "The most common country for Netflix content is likely the country that filled in the null values for the 'country' column\n",
        "The 'cast' column is important in the dataset, as there were null values that needed to be filled in order to keep the data complete\n",
        "The 'date_added' and 'rating' columns may not be important in the dataset, as they were dropped due to a small number of null values. However, this would depend on the specific analysis being done.\n",
        "The 'director' column was dropped, which may indicate that it is not a useful feature for the analysis.."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - **1.Type**"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "sns.set_style('darkgrid')\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='type', data=df, palette='pastel')\n",
        "#labeling of values\n",
        "plt.title('Number of Movies and TV Shows', fontsize=14)\n",
        "plt.xlabel('Type', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "#Visualization of number of movies and tv shows\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "countplot (which is a type of bar chart) may be a good choice for visualizing categorical data, such as the number of movies and TV shows on Netflix. This is because a countplot displays the frequency of each category in a clear and easy-to-understand way.."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of movies on Netflix is greater than the number of TV shows, with 5372 movies and 2398 TV shows currently available on the platform."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insight that there are more movies on Netflix than TV shows is unlikely to have a significant positive or negative business impact on its own. However, this information could be used in conjunction with other insights and data to inform business decisions.\n",
        "\n",
        "For example, if Netflix notices that TV shows are more popular with its subscribers than movies, it may decide to focus more on acquiring TV show content. Alternatively, if it sees that its original movie productions are gaining popularity, it may decide to invest more in that area.\n",
        "\n",
        "In terms of negative growth, the specific insight that there are more movies than TV shows on Netflix is unlikely to have a negative impact on its own. However, if Netflix were to ignore the preferences of its subscribers and continue to acquire movies over TV shows, it could potentially lose subscribers who are looking for more TV show content. Additionally, if Netflix's competitors start to offer more TV shows, it may lose market share if it does not respond by acquiring more TV show content."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - **2.Rating**"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "df['rating']"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = {\n",
        "    'TV-PG': 'Older Kids',\n",
        "    'TV-MA': 'Adults',\n",
        "    'TV-Y7-FV': 'Older Kids',\n",
        "    'TV-Y7': 'Older Kids',\n",
        "    'TV-14': 'Teens',\n",
        "    'R': 'Adults',\n",
        "    'TV-Y': 'Kids',\n",
        "    'NR': 'Adults',\n",
        "    'PG-13': 'Teens',\n",
        "    'TV-G': 'Kids',\n",
        "    'PG': 'Older Kids',\n",
        "    'G': 'Kids',\n",
        "    'UR': 'Adults',\n",
        "    'NC-17': 'Adults'\n",
        "}\n",
        "\n",
        "df['target_ages'] = df['rating'].map(ratings)"
      ],
      "metadata": {
        "id": "ee6PdBV8TUhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert 'type' column to categorical data type\n",
        "df['type'] = pd.Categorical(df['type'])\n",
        "\n",
        "# create a new categorical column 'target_ages' with specified categories\n",
        "df['target_ages'] = pd.Categorical(df['target_ages'], categories=['Kids', 'Older Kids', 'Teens', 'Adults'])\n"
      ],
      "metadata": {
        "id": "K2zGJjCSTxS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "0p53_t2XTzi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating two extra columns\n",
        "tv_shows=df[df['type']=='TV Show']\n",
        "movies=df[df['type']=='Movie']"
      ],
      "metadata": {
        "id": "5NE8Dqj-T6Lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# group TV shows by 'rating' and count the number of shows in each rating category\n",
        "tv_ratings = tv_shows.groupby(['rating'])['show_id'].count().reset_index(name='count').sort_values(by='count',ascending=False)\n",
        "\n",
        "# set figure dimensions\n",
        "fig_dims = (14,7)\n",
        "\n",
        "# create a figure and axis object with specified dimensions\n",
        "fig, ax = plt.subplots(figsize=fig_dims)\n",
        "\n",
        "# create a point plot using Seaborn's pointplot() function, with 'rating' on the x-axis and 'count' on the y-axis\n",
        "sns.pointplot(x='rating',y='count',data=tv_ratings)\n",
        "\n",
        "# set the plot title and font size\n",
        "plt.title('TV Show Ratings',size='20')\n",
        "\n",
        "# display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PAbuc6l8T9qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a color palette for the different target age groups\n",
        "colors = [\"#FFC300\", \"#FF5733\", \"#C70039\", \"#900C3F\"]\n",
        "\n",
        "# plot a countplot to show the movie ratings based on target age groups\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.title('Movie Ratings by Target Age Group')\n",
        "\n",
        "sns.countplot(x=movies['rating'], hue=movies['target_ages'], data=movies, \n",
        "              order=movies['rating'].value_counts().index, palette=colors)\n",
        "\n",
        "# add a legend to the plot\n",
        "plt.legend(title='Target Age Group', loc='upper right', labels=['Kids', 'Older Kids', 'Teens', 'Adults'])\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GB79ENUpU922"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose this chart because it effectively shows the distribution of TV show ratings in a clear and concise manner. The bars allow for easy comparison between the different ratings, and the ordering by count from highest to lowest further emphasizes the dominance of TV-MA. Overall, this chart provides a quick and informative overview of the ratings landscape for TV shows on Netflix.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the dataset, TV-MA is the most common rating for TV shows, with the highest number of occurrences in the 'rating' column. This indicates that a significant portion of the TV shows available on Netflix are intended for adult audiences.According to the dataset, TV-MA is the most common rating for both movies and TV shows. This indicates that a significant portion of the content available on Netflix is intended for adult audiences. Specifically, TV-MA has the highest number of occurrences in the 'rating' column for TV shows, while for movies it is also the most common rating. This suggests that Netflix's content caters to a primarily adult demographic, with a focus on mature and potentially controversial themes."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights can have a positive impact on Netflix's business strategy. Knowing that TV-MA is the most common rating for both movies and TV shows, Netflix can continue to focus on producing and acquiring content that appeals to adult audiences. This can help attract and retain subscribers who are interested in mature and potentially controversial themes. Additionally, understanding the target age groups for different ratings can help Netflix tailor its marketing and promotional efforts to specific audiences.\n",
        "\n",
        "However, there is a potential negative impact as well. Some subscribers may be put off by the prevalence of mature content, particularly if they are looking for family-friendly programming. This could lead to a loss of subscribers who are not interested in or comfortable with adult themes. It is important for Netflix to balance its content offerings to appeal to a wide range of viewers and avoid alienating any particular demographic."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - **3.Release Year**"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a line chart to visualize the number of movies and TV shows released each year\n",
        "#Extracting the count of movies and TV shows for each year\n",
        "movies_year = movies['release_year'].value_counts().sort_index(ascending=False)\n",
        "tvshows_year = tv_shows['release_year'].value_counts().sort_index(ascending=False)\n",
        "\n",
        "#Creating a line plot using Seaborn\n",
        "sns.set(style='whitegrid', font_scale=1.2)\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "ax = sns.lineplot(x=movies_year.index, y=movies_year.values, color='maroon', label='Movies', linewidth=2.5, marker='o')\n",
        "ax = sns.lineplot(x=tvshows_year.index, y=tvshows_year.values, color='blue', label='TV Shows', linewidth=2.5, marker='o')\n",
        "\n",
        "#Customizing the plot\n",
        "plt.xticks(rotation=90)\n",
        "ax.set_xlabel('Release Year', fontsize=14)\n",
        "ax.set_ylabel('Number of Titles', fontsize=14)\n",
        "ax.set_title('Production Growth Yearly', fontsize=18, pad=15)\n",
        "plt.legend(fontsize=14)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the last 20 years from the dataset\n",
        "last_20_years = range(2001, 2020)\n",
        "\n",
        "# Filter the dataset to only include movies from the last 20 years\n",
        "movies_last_20_years = movies[movies['release_year'].isin(last_20_years)]\n",
        "\n",
        "# Create a count plot of the number of movies released per year\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.countplot(x='release_year', data=movies_last_20_years, palette='mako', order=last_20_years)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.xlabel('Year of Release')\n",
        "plt.ylabel('Number of Movies Released')\n",
        "plt.title('Number of Movies Released per Year in the Last 20 Years')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dtBIOp1Icati"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tvshows_year"
      ],
      "metadata": {
        "id": "a7PhNF8Ddefe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filter for movies released in the last 15 years\n",
        "movies_last_15_years = df[df['release_year'] >= 2008]\n",
        "\n",
        "# create a countplot with horizontal bars\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.countplot(y='release_year', data=movies_last_15_years, order=movies_last_15_years['release_year'].value_counts().index[:15])\n",
        "plt.title('Number of Movies Released per Year (2008-2022)', fontsize=16)\n",
        "plt.xlabel('Number of Movies')\n",
        "plt.ylabel('Release Year')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cf2WtcRidi4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "ncLy09-ee-BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding columns of month and year of addition\n",
        "\n",
        "df['month'] = pd.DatetimeIndex(df['date_added']).month\n",
        "df.head()"
      ],
      "metadata": {
        "id": "4jBBtlmKfFqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best chart to use would be a line chart or a bar chart to display the number of movies and TV shows released per year from 2015 to 2020. This will allow for a clear comparison between the number of movies and TV shows released in each year and identify any trends or patterns in the data. Additionally, a stacked bar chart or a stacked area chart can also be used to show the proportion of movies and TV shows released in each year.\n",
        "\n",
        "As for why I chose this specific chart, I believe it is because it effectively conveys the message that the number of movies released on Netflix is growing faster than the number of TV shows. It also highlights the trend of increased production of movies and TV shows after 2015, followed by a drop after 2020. Overall, this chart is useful in illustrating the growth and changes in Netflix's content over the years.."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The years 2017 and 2018 had the highest number of movie releases, while 2020 had the highest number of TV show releases.\n",
        "\n",
        "The growth rate of movie releases on Netflix is significantly faster than that of TV shows.\n",
        "\n",
        "Since 2015, there has been a substantial increase in the number of movies and TV show episodes available on Netflix.\n",
        "\n",
        "However, there has been a notable drop in the number of movies and TV show episodes produced after 2020.\n",
        "\n",
        "It appears that Netflix has given more attention to increasing its movie content rather than TV shows, as the growth rate of movies has been much more significant than that of TV shows."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These insights may have a positive business impact for Netflix, as they show that increasing their movie content could be a successful strategy. By providing a larger selection of movies, they may attract more viewers and retain their existing audience. However, the sharp drop in content production after 2020 could be a concern for the company, as it may indicate that they are facing production challenges or a lack of investment in content creation. If this trend continues, it could lead to negative growth for the company, as viewers may turn to other streaming services with a larger selection of content.\n",
        "\n",
        "In conclusion, while the insights gained from the analysis suggest potential opportunities for Netflix, it is important to continue monitoring trends and adapting to changes in the market to ensure continued growth and success."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - **4.Release_month**"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "#visualization of month of movie release\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.countplot(x='month', data=df, palette='Set2')\n",
        "plt.title('Countplot of Month')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Countplot of Month by Type\n",
        "fig, ax = plt.subplots(figsize=(15, 6))\n",
        "\n",
        "sns.countplot(x='month', hue='type', data=df, palette='Set2', ax=ax, edgecolor='black', linewidth=2.5)\n",
        "ax.set_title('Countplot of Month by Type', fontsize=16)\n",
        "ax.set_xlabel('Month', fontsize=14)\n",
        "ax.set_ylabel('Count', fontsize=14)\n",
        "ax.legend(fontsize=12, title='Type', title_fontsize=12)\n",
        "sns.despine()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cWsR5SmCiutg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked the specific chart, which is a countplot with hue, because it allows us to easily visualize and compare the number of movies and TV shows added to Netflix each month. The use of hue in the countplot enables us to see the contribution of each type (i.e. movies and TV shows) to the total count for each month, making it easier to identify any patterns or trends in the data.\n",
        "\n",
        "In this case, we can clearly see that from October to January, there was a peak in the number of movies and TV shows added to Netflix. This is important information for Netflix and content creators, as it may suggest a time period when people are more likely to be interested in watching new content, and thus, a potentially more profitable time to release new content."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the countplot, it appears that Netflix adds the highest number of movies and TV shows during the period between October and January. This period seems to be the busiest time of year for Netflix in terms of adding new content to its platform."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insight that the most content is added to Netflix from October to January can potentially help create a positive business impact. This information can be useful for Netflix to plan their content acquisition and release schedule in a way that maximizes user engagement during these months. For example, Netflix can prioritize acquiring and releasing more popular titles during these months to attract and retain users.\n",
        "\n",
        "However, it's important to note that the information from the countplot alone may not be sufficient to create a significant positive impact. Netflix would need to analyze user viewing patterns and preferences, as well as monitor competition and market trends, to create a comprehensive content acquisition and release strategy.\n",
        "\n",
        "Regarding negative growth, the countplot alone does not provide any insights that would lead to negative growth. However, if Netflix were to solely rely on the countplot information and ignore other important factors such as user preferences, changing market trends, and competition, then there is a risk of negative growth due to inadequate content selection and acquisition strategy."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - **5.Genre**"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "#Top 10 genres of movies\n",
        "top10_movies = movies['listed_in'].value_counts().index[0:10]\n",
        "#Visualization of code\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.countplot(y='listed_in', data=movies, order=top10_movies, palette='muted')\n",
        "plt.title('Top 10 Genres of Movies', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Count', fontsize=14)\n",
        "plt.ylabel('Genre', fontsize=14)\n",
        "sns.despine()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Top 10 Genres of Tv shows\n",
        "top10_tvshows = tv_shows['listed_in'].value_counts().index[0:10]\n",
        "#Visualization\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.countplot(y='listed_in', data=tv_shows, order=top10_tvshows, palette='pastel')\n",
        "plt.title('Top 10 Genres of TV Shows', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Count', fontsize=14)\n",
        "plt.ylabel('Genre', fontsize=14)\n",
        "sns.despine()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wr52DGA-lokk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the count of netflix shows and tv shows."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix offers a diverse range of TV show genres, each with its own unique flavor and appeal. However, one genre that stands out as a perennial favorite among viewers of all ages is kids TV.\n",
        "\n",
        "With an impressive selection of animated and live-action shows, Netflix's kids TV category is the perfect destination for families looking for high-quality, entertaining content that is both fun and educational. From beloved classics like SpongeBob SquarePants and Power Rangers to exciting new series like Carmen Sandiego and The Dragon Prince, Netflix's kids TV library has something for every young viewer.\n",
        "\n",
        "Moreover, Netflix's kids TV category is designed with parents in mind, offering a safe and secure viewing environment that allows them to have peace of mind while their kids enjoy their favorite shows. The parental controls feature allows parents to set age-appropriate content filters, monitor viewing history, and restrict access to certain shows or movies.\n",
        "\n",
        "So, whether you're looking for a way to keep your little ones entertained on a rainy day, or just want to bond with your family over a great TV show, Netflix's kids TV category is the perfect place to start. With its vast selection of entertaining and educational content, it's no wonder that kids TV remains one of the top genres on the platform."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The top genre for TV shows on Netflix is kids TV, which includes a range of educational and entertaining content for children of all ages. This includes popular shows such as \"Paw Patrol\", \"Peppa Pig\", \"The Magic School Bus\", and \"Stranger Things.\"\n",
        "\n",
        "The insights gained from this information could definitely have a positive business impact. By knowing which genres are most popular, Netflix can tailor their content offerings and marketing strategies to appeal to their target audience. For example, they could invest more in producing high-quality kids shows and promoting them heavily to parents with young children.\n",
        "\n",
        "However, there could also be some negative growth associated with this trend. For example, if Netflix were to focus too heavily on kids TV shows and neglect other genres, they could risk losing older viewers who are looking for more mature content. Additionally, if the quality of their kids programming were to decline or if they were to lose the rights to popular shows, this could also hurt their business. It's important for Netflix to strike a balance between catering to their core audience while still offering a diverse range of content to appeal to a broader audience."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - **6.Duration**"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# Create a figure and set its size\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "# Extract the duration values as integers using regex and plot a histogram\n",
        "sns.histplot(movies['duration'].str.extract('(\\d+)').astype(int), kde=False, color='red')\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title('Distribution of Movie Durations', fontweight='bold')\n",
        "\n",
        "# Set the x-axis label\n",
        "plt.xlabel('Duration (minutes)')\n",
        "\n",
        "# Set the y-axis label\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the figure size\n",
        "plt.figure(figsize=(30, 6))\n",
        "\n",
        "# Create a count plot of TV show durations\n",
        "sns.countplot(x=tv_shows['duration'], data=tv_shows, order=tv_shows['duration'].value_counts().index)\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title(\"Distribution of TV Show Durations\", fontweight='bold')\n",
        "\n",
        "# Set the x-axis label\n",
        "plt.xlabel(\"Duration (seasons)\")\n",
        "\n",
        "# Set the y-axis label\n",
        "plt.ylabel(\"Count\")\n",
        "\n",
        "# Rotate the x-axis labels\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CzHdhfHdnzeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the duration values as integers using regex\n",
        "movies['minute'] = movies['duration'].str.extract('(\\d+)').apply(pd.to_numeric)\n",
        "\n",
        "# Calculate the average movie duration by rating\n",
        "duration_year = movies.groupby(['rating'])['minute'].mean()\n",
        "\n",
        "# Create a DataFrame to store the results and sort by average duration\n",
        "duration_df = pd.DataFrame(duration_year).sort_values('minute')\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Create a bar plot of the average movie duration by rating\n",
        "ax = sns.barplot(x=duration_df.index, y=duration_df.minute)\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title(\"Average Movie Duration by Rating\", fontweight='bold')\n",
        "\n",
        "# Set the x-axis label\n",
        "plt.xlabel(\"Rating\")\n",
        "\n",
        "# Set the y-axis label\n",
        "plt.ylabel(\"Average Duration (minutes)\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "16Qp0a0KooFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Movie duration and rating are two key factors that can influence a viewer's decision to watch a movie. By creating a chart that visualizes the relationship between these two variables, it becomes easier to identify patterns and trends. For example, the chart mentioned in your question highlights that NC-17 movies tend to have longer runtimes than movies with other ratings, which could be a useful insight for filmmakers and movie studios.\n",
        "\n",
        "Similarly, the chart also shows that TV-Y rated movies tend to have shorter runtimes, which could be useful for parents looking for age-appropriate content for their children. Overall, a chart comparing movie durations and ratings can provide valuable information for a variety of stakeholders in the movie industry, including filmmakers, studios, distributors, and viewers."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When analyzing the movie durations, it was observed that the majority of the movies have a duration between 50 to 150 minutes. On the other hand, the TV shows have a large number of single-season shows, which indicates that most of the TV shows on Netflix are relatively new.\n",
        "\n",
        "Furthermore, the analysis showed that movies with a rating of NC-17 have the longest average duration. This might be because the movies with such a rating can explore more mature themes and include more explicit content, which requires a longer runtime to tell a compelling story.\n",
        "\n",
        "In contrast, the analysis also revealed that movies with a TV-Y rating, which is suitable for all children, have the shortest runtime on average. This suggests that the movies with this rating tend to be shorter and may have simpler plots and themes that are suitable for younger audiences."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights can potentially help create a positive business impact as it allows movie studios and streaming platforms to better understand their audience and tailor their content accordingly. For example, if they notice that movies with an NC-17 rating tend to have longer average runtimes, they may choose to allocate more resources towards creating longer, more mature content for adult audiences. Similarly, if they notice that TV-Y rated movies tend to have shorter runtimes, they may choose to focus on creating shorter, more family-friendly content that can hold the attention of younger viewers.\n",
        "\n",
        "However, there could also be insights that lead to negative growth. For example, if studios or streaming platforms notice that most TV shows only consist of a single season, they may hesitate to invest in producing more seasons of a show, even if it has a dedicated fanbase. This could lead to a lack of growth in terms of audience and revenue for certain shows or franchises. Additionally, if they notice that movies with certain ratings consistently perform poorly in terms of ratings or box office revenue, they may choose to avoid investing in similar projects in the future, which could limit the variety of content available to audiences. Ultimately, it is important for businesses to carefully consider all of the insights gained and weigh the potential positive and negative impacts before making decisions that could affect their growth."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - **7.Country**"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# create a figure with the desired size\n",
        "plt.figure(figsize=(18,5))\n",
        "\n",
        "# create a countplot with the 'country' column\n",
        "# order the bars in descending order by value counts\n",
        "# limit the plot to only show the top 15 countries\n",
        "# hue the plot by content type ('TV Show' or 'Movie')\n",
        "sns.countplot(x=df['country'], order=df['country'].value_counts().index[0:15], hue=df['type'])\n",
        "\n",
        "# rotate the x-axis tick labels by 50 degrees for better visibility\n",
        "plt.xticks(rotation=50)\n",
        "\n",
        "# set the plot title and font size\n",
        "plt.title('Top 15 countries with most contents', fontsize=15, fontweight='bold')\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#top_two countries where netflix is most popular\n",
        "country=df['country'].value_counts().reset_index()\n",
        "country"
      ],
      "metadata": {
        "id": "0GuXrb_3r1Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 10 countries by count of titles\n",
        "country_order = df['country'].value_counts()[:10].index\n",
        "\n",
        "# Create a dataframe with count of movie and TV show for each country\n",
        "content_data = df[['type', 'country']].groupby('country')['type'].value_counts().unstack().loc[country_order]\n",
        "\n",
        "# Add a column for total count of titles\n",
        "content_data['total'] = content_data.sum(axis=1)\n",
        "\n",
        "# Calculate the ratio of movie and TV show for each country\n",
        "content_data_ratio = (content_data.T / content_data['total']).T[['Movie', 'TV Show']]\n",
        "\n",
        "# Sort the dataframe by movie ratio and plot the horizontal bar chart\n",
        "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
        "content_data_ratio.sort_values(by='Movie').plot(kind='barh', stacked=True, ax=ax)\n",
        "\n",
        "# Set the x-axis label and title\n",
        "ax.set_xlabel('Ratio of Titles', fontsize=14)\n",
        "ax.set_title('Ratio of Movie and TV Show by Country', fontsize=18)\n",
        "\n",
        "# Set the legend\n",
        "handles, labels = ax.get_legend_handles_labels()\n",
        "ax.legend(reversed(handles), reversed(labels), fontsize=12, loc='upper right')"
      ],
      "metadata": {
        "id": "ujGdO6FSsS4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing data for heatmap\n",
        "df['count'] = 1\n",
        "data = df.groupby('country')[['country','count']].sum().sort_values(by='count',ascending=False).reset_index()[:10]\n",
        "data = data['country']\n",
        "\n",
        "\n",
        "df_heatmap = df.loc[df['country'].isin(data)]\n",
        "df_heatmap = pd.crosstab(df_heatmap['country'],df_heatmap['target_ages'],normalize = \"index\").T\n",
        "df_heatmap"
      ],
      "metadata": {
        "id": "Fyr98czcwa95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the given information, we can say that the United States has the highest number of content on Netflix, followed by India. Additionally, India has the highest number of movies on Netflix.\n",
        "\n",
        "To communicate this information visually, a bar chart or a horizontal bar chart would be a good choice. The bar chart can show the number of titles for each country side by side, making it easy to compare them. A horizontal bar chart can also work well, especially if we want to show the countries in descending order of title count.."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix has the highest number of content in the United States, followed by India. India has the highest number of movies on Netflix."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to our analysis, the United States has the highest number of content on Netflix, followed by India. Interestingly, India has the highest number of movies on Netflix.\n",
        "\n",
        "These insights can be useful for Netflix in a number of ways. For example, they could use this information to tailor their content recommendations to users based on their geographic location. They could also use this information to determine which types of content to focus on producing in the future.\n",
        "\n",
        "However, there are also some potential negative impacts to consider. For example, if Netflix focuses too heavily on producing content for specific countries or regions, they may neglect other markets and potentially lose viewership and revenue as a result. Additionally, if they rely too heavily on one particular type of content (e.g. movies), they may miss out on opportunities to attract viewers who prefer other types of content (e.g. TV shows or documentaries).\n",
        "\n",
        "Overall, while the insights gained from our analysis can certainly be useful for informing business decisions at Netflix, it's important to approach these insights with a balanced and nuanced perspective, taking into account potential positive and negative impacts."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - **8.Originals**"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "df['date_added'] = pd.to_datetime(df['date_added'])\n",
        "movies['year_added'] = df['date_added'].dt.year\n",
        "df"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new column 'originals' which indicates whether a movie is an original or not\n",
        "movies['originals'] = np.where(movies['release_year'] == movies['year_added'], 'Yes', 'No')\n",
        "\n",
        "# Create a pie chart showing the percentage of originals and others in the dataset\n",
        "fig, ax = plt.subplots(figsize=(5,5), facecolor=\"#363336\")\n",
        "ax.patch.set_facecolor('#363336')\n",
        "\n",
        "# Specify the explode parameter to create some separation between the slices\n",
        "explode = (0, 0.1)\n",
        "\n",
        "# Use value_counts() to count the number of movies in each category\n",
        "# and plot a pie chart using the ax.pie() method\n",
        "ax.pie(movies['originals'].value_counts(), explode=explode, autopct='%.2f%%', labels=['Others', 'Originals'],\n",
        "       shadow=True, startangle=90, textprops={'color': \"black\", 'fontsize': 20}, colors=['red', '#F5E9F5'])\n",
        "\n",
        "# Set the title for the plot\n",
        "ax.set_title(\"Percentage of Originals vs Others in Movies\", color='white', fontsize=20)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vdX3fvF7xyVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the percentage of originals vs others."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While Netflix is known for producing original content, it is interesting to note that only 30% of the movies available on the platform were actually released by Netflix themselves. The remaining 70% of movies were added to Netflix after being released by different modes, such as theaters or other streaming platforms.\n",
        "\n",
        "This fact highlights the vast library of movies that Netflix has acquired over the years, providing viewers with a diverse range of content from all around the world. From classic Hollywood films to foreign cinema, Netflix offers something for everyone, regardless of their interests or preferences.\n",
        "\n",
        "So, the next time you're scrolling through Netflix's extensive movie catalog, remember that only a small fraction of what you see is actually original content. The majority of the movies available have been acquired and added to the platform, providing viewers with a seemingly endless supply of entertainment options."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the positive side, the fact that 70% of movies added on Netflix were released earlier by a different mode suggests that Netflix is able to acquire popular content that has already been released elsewhere. This can be seen as a strength, as it allows Netflix to offer a wider variety of content to its customers without incurring the high costs of producing original content.\n",
        "\n",
        "Furthermore, the fact that 30% of movies released on Netflix suggests that Netflix is investing in creating its own original content. This can be seen as a positive as it allows Netflix to differentiate itself from competitors and create unique content that can attract new customers and retain existing ones.\n",
        "\n",
        "However, on the negative side, if Netflix is not able to produce original content that is as popular as the acquired content, it could lead to a decline in subscribers. Additionally, if Netflix relies too heavily on acquired content, it may not be able to negotiate favorable licensing agreements with content providers, which could lead to increased costs and decreased profitability."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "# Preparing data for heatmap\n",
        "df['count'] = 1\n",
        "data = df.groupby('country')[['country','count']].sum().sort_values(by='count',ascending=False).reset_index()[:10]\n",
        "data = data['country']\n",
        "\n",
        "\n",
        "df_heatmap = df.loc[df['country'].isin(data)]\n",
        "df_heatmap = pd.crosstab(df_heatmap['country'],df_heatmap['target_ages'],normalize = \"index\").T\n",
        "df_heatmap"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the heatmap\n",
        "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
        "\n",
        "country_order2 = ['United States', 'India', 'United Kingdom', 'Canada', 'Japan', 'France', 'South Korea', 'Spain',\n",
        "       'Mexico']\n",
        "\n",
        "age_order = ['Adults', 'Teens', 'Older Kids', 'Kids']\n",
        "\n",
        "sns.heatmap(df_heatmap.loc[age_order,country_order2],cmap=\"YlGnBu\",square=True, linewidth=2.5,cbar=False,\n",
        "            annot=True,fmt='1.0%',vmax=.6,vmin=0.05,ax=ax,annot_kws={\"fontsize\":12})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nA_5Iltjwwyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know the relation between variables."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the US and UK are closely aligned with their Netflix target ages, but radically different from, example, India or Japan!\n",
        "\n",
        "Also, Mexico and Spain have similar content on Netflix for different age groups."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - -Netflix has the highest number of content in the United States, followed by India. India has the highest number of movies on Netflix."
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis (H0): The average number of movies on Netflix in the United States is equal to the average number of movies on Netflix in India.\n",
        "Alternative hypothesis (H1): The average number of movies on Netflix in the United States is greater than the average number of movies on Netflix in India.."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "# Filter movies only\n",
        "movies = df[df.type == 'Movie']\n",
        "\n",
        "# Filter by country\n",
        "us_movies = movies[movies.country == 'United States']\n",
        "india_movies = movies[movies.country == 'India']\n",
        "\n",
        "# Perform t-test\n",
        "t, p = ttest_ind(us_movies['release_year'], india_movies['release_year'], equal_var=False)\n",
        "\n",
        "# Print the results\n",
        "alpha = 0.05\n",
        "if p < alpha:\n",
        "    print(\"Reject null hypothesis. The average number of movies on Netflix in the United States is greater than the average number of movies on Netflix in India.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis. The average number of movies on Netflix in the United States is equal to the average number of movies on Netflix in India.\")"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " I used a two-sample t-test (also known as an independent samples t-test or unpaired t-test) to obtain the p-value. Specifically, I used the ttest_ind function from the scipy.stats module to perform the t-test. This test is appropriate for comparing the means of two independent samples, which is what we're doing here by comparing the number of movies on Netflix in the United States and India.\n",
        "\n",
        "It's worth noting that I assumed that the variances of the two populations are not equal (i.e., I set equal_var=False in the ttest_ind function), since it's reasonable to expect that the variances of the number of movies on Netflix in the United States and India could differ. However, if we had reason to believe that the variances were equal, we could use a pooled t-test instead.."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the two-sample t-test because it's appropriate for comparing the means of two independent samples, which is exactly what we're doing here. We have two independent samples of movies on Netflix in the United States and India, and we want to test whether the mean number of movies in the United States is significantly different from the mean number of movies in India.\n",
        "\n",
        "The t-test is also appropriate because the population standard deviations are unknown, and we're working with relatively small sample sizes (compared to the total number of movies on Netflix), so we need to use the sample standard deviations to estimate the population standard deviations.\n",
        "\n",
        "Additionally, the t-test assumes that the data are normally distributed (or approximately normally distributed), which is a reasonable assumption for this type of data.\n",
        "\n",
        "Overall, the two-sample t-test is a widely used and reliable statistical test for comparing the means of two independent samples, making it a good choice for this analysis.."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - According to the countplot, it appears that Netflix adds the highest number of movies and TV shows during the period between October and January. This period seems to be the busiest time of year for Netflix in terms of adding new content to its platform."
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Null hypothesis(H0)-there is no significant difference in the number of movies and TV shows added by Netflix across different months. \n",
        "alternative hypothesis-there is a significant difference in the number of movies and TV shows added by Netflix across different months."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Convert the \"date_added\" column to datetime format\n",
        "df[\"date_added\"] = pd.to_datetime(df[\"date_added\"])\n",
        "\n",
        "# Extract the month from the \"date_added\" column\n",
        "df[\"month_added\"] = df[\"date_added\"].dt.month_name()\n",
        "\n",
        "# Create a contingency table of the number of new movies and TV shows added by month\n",
        "contingency_table = pd.crosstab(df[\"type\"], df[\"month_added\"])\n",
        "\n",
        "# Perform a chi-square test for independence\n",
        "chi2_statistic, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "\n",
        "print(\"Chi-square statistic:\", chi2_statistic)\n",
        "print(\"P-value:\", p_value)"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To obtain the p-value, we have performed a chi-square test for independence. The chi-square test is used to determine if there is a significant association between two categorical variables. In this case, we wanted to test if there was a significant association between the time of year and the number of new movies and TV shows added to Netflix. The test involves comparing the observed frequencies of the contingency table (which shows the distribution of the data) to the expected frequencies under the assumption of independence. The test statistic is calculated as the sum of squared differences between the observed and expected frequencies, and its distribution follows a chi-square distribution. The p-value is then calculated as the probability of obtaining a test statistic as extreme or more extreme than the observed test statistic, assuming the null hypothesis (independence) is true. If the p-value is less than the significance level (usually 0.05), we reject the null hypothesis and conclude that there is a significant association between the two variables.."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We chose the chi-square test for independence because we were interested in testing for a potential association between two categorical variables: the time of year and the number of new movies and TV shows added to Netflix. The chi-square test for independence is commonly used for this type of analysis, where we want to determine if the observed distribution of frequencies differs significantly from the expected distribution under the assumption of independence between the two variables. The test allows us to calculate a p-value, which indicates the strength of evidence against the null hypothesis of independence. If the p-value is less than the significance level (usually 0.05), we reject the null hypothesis and conclude that there is a significant association between the two variables. Therefore, the chi-square test for independence is a suitable statistical test to use for this analysis.."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - The number of movies on Netflix is greater than the number of TV shows, with 5372 movies and 2398 TV shows currently available on the platform."
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis: The number of movies and TV shows on Netflix is not significantly different.\n",
        "\n",
        "Alternative hypothesis: The number of movies on Netflix is significantly greater than the number of TV shows."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "# Count the number of movies and TV shows\n",
        "n_movies = df[df['type'] == 'Movie'].count()['type']\n",
        "n_tv_shows = df[df['type'] == 'TV Show'].count()['type']\n",
        "\n",
        "# Set the counts and sample sizes for the z-test\n",
        "counts = [n_movies, n_tv_shows]\n",
        "nobs = [len(df), len(df)]\n",
        "\n",
        "# Perform the z-test assuming equal proportions\n",
        "z_stat, p_val = proportions_ztest(counts, nobs, value=0, alternative='larger')\n",
        "\n",
        "# Print the results\n",
        "print('Number of movies:', n_movies)\n",
        "print('Number of TV shows:', n_tv_shows)\n",
        "print('z-statistic:', z_stat)\n",
        "print('p-value:', p_val)"
      ],
      "metadata": {
        "id": "aMZEp0BwKBBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used a two-sample z-test for proportions to obtain the p-value. The null hypothesis for the test is that the proportion of movies and TV shows on Netflix is equal, while the alternative hypothesis is that the proportion of movies is greater than the proportion of TV shows. We used the proportions_ztest() function from the statsmodels library to perform the test. The function calculates the z-score and the p-value for the test based on the sample proportions, sample sizes, and the specified null hypothesis value."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the two-sample z-test for proportions to compare the number of movies and TV shows on Netflix because the data consists of two categorical variables (movie or TV show), and we want to test if there is a significant difference between the proportions of these categories in the population. The two-sample z-test for proportions is an appropriate test to use when we have two independent samples, and we want to compare the proportion of successes in each sample. In this case, a success refers to a movie or TV show. The test assumes that the samples are large enough to apply the normal approximation to the binomial distribution. Since we have a large sample size in this case, we can use the z-test for proportions to test the hypothesis of interest.."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning**"
      ],
      "metadata": {
        "id": "Ph0afZWIbS--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Data %\n",
        "round(df.isna().sum()/len(df)*100, 2).sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "nk1k37s7nDk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "df[['director','cast','country']] = df[['director','cast','country']].fillna(' ')\n",
        "df.dropna(axis=0, inplace=True)"
      ],
      "metadata": {
        "id": "X68FFFIFnV0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for null values after treating them.\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "HAXKDlXinp26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# boxplot for outlier detection\n",
        "sns.boxplot(data=df)"
      ],
      "metadata": {
        "id": "o2oQibF4n5WI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "\n",
        "# plotting graph\n",
        "fig,ax = plt.subplots(1,2, figsize=(15,5))\n",
        "\n",
        "# Display boxplot and dist plot.\n",
        "sns.distplot(x=df['release_year'], ax=ax[0])\n",
        "sns.boxplot(data=df, ax=ax[1])\n"
      ],
      "metadata": {
        "id": "BX2z1GXVbQ6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Except for the release year, almost all of the data are presented in text format.\n",
        "\n",
        "2.The textual format contains the data we need to build a cluster/building model. Therefore, there is no need to handle outliers."
      ],
      "metadata": {
        "id": "46F8Kva6b5iH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.Textual Data Preprocessing**"
      ],
      "metadata": {
        "id": "0fM9C1OrdscP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is textual data preprocessing?**\n",
        "\n",
        "Textual data preprocessing is the process of preparing text data for analysis or modeling. It includes a series of steps that are applied to raw text data in order to clean, organize and standardize it so that it can be easily analyzed or used as input for natural language processing or machine learning models. The preprocessing steps typically include tokenization, stop-word removal, stemming or lemmatization, lowercasing, removing punctuation, and removing numbers. The goal of textual data preprocessing is to prepare the data for further analysis and modeling by removing irrelevant information and standardizing the format of the text. This can help improve the accuracy and effectiveness of the analysis or modeling."
      ],
      "metadata": {
        "id": "wc2EOy3Fd5N-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modeling Approch**\n",
        "\n",
        "Imagine you're organizing a cluttered closet - you want to group items that have similar attributes to make them easier to find. Similarly, clustering is a technique used to group together similar data points. In this case, we're applying clustering to a set of movies to identify patterns and group them based on their attributes.\n",
        "\n",
        "Before clustering, we need to prepare the textual data. Just like sorting clothes by color or size, we sort words by their importance. We use text preprocessing techniques like lowercasing, removing punctuation marks, and eliminating stopwords (common words like \"the\", \"and\", etc.) that don't add much meaning. Stemming or lemmatization is also used to normalize the words and reduce them to their base form. Finally, tokenization is applied to break the text into smaller units like sentences or words.\n",
        "\n",
        "Now that we've tidied up the data, we can start clustering. But first, we need to reduce the dimensionality of the data - just like folding clothes to save space in the closet. Various algorithms can be used to cluster the movies, and we can use techniques to determine the optimal number of clusters.\n",
        "\n",
        "Once we've built the optimal number of clusters, we can explore their contents using wordclouds. Think of wordclouds as a way to showcase the unique personality of each cluster. We can visually represent the most frequently occurring words in each cluster in a creative and engaging way. By doing so, we gain insights into the characteristics that make each cluster unique and identify the patterns that bind them together."
      ],
      "metadata": {
        "id": "7k_wc0IYek8A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Selecting Attributes**"
      ],
      "metadata": {
        "id": "m9vMGkCdey3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating tags column using all text column which one is used for model building purpose.\n",
        "df['tags'] = df['description'] + df['listed_in'] + df['rating'] + df['cast'] + df['country'] + df['director']"
      ],
      "metadata": {
        "id": "wQ5vIyLqinM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tags[0]"
      ],
      "metadata": {
        "id": "8VTgk1VXiqzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have successfully added all the necessary data into a single column."
      ],
      "metadata": {
        "id": "FdCRdWm6pOIx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Removing Stopwords and Lower Casing.\n",
        "Removing stop words and lowercasing words are common pre-processing steps in natural language processing (NLP) tasks.\n",
        "\n",
        "Stop words are words that are commonly used in a language but do not convey much meaning on their own, such as \"a,\" \"an,\" \"the,\" and \"is.\" These words can add noise to the data and can sometimes affect the performance of NLP models, so they are often removed as a pre-processing step.\n",
        "\n",
        "Lowercasing words is the process of converting all the words in a text to lowercase. This is a common pre-processing step in NLP tasks, as it can be useful for a few reasons:\n",
        "\n",
        "Case differences can be ignored: By lowercasing the words, you can treat words with different capitalization as the same word, which can be useful in tasks such as information retrieval or text classification where case differences are not important.\n",
        "Vocabulary size is reduced: Lowercasing the words can also reduce the size of the vocabulary, which can make it easier to work with larger texts or texts in languages with a high number of inflected forms."
      ],
      "metadata": {
        "id": "eAiTaTjLpYbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download the stop words list if it is not already downloaded\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# create a set of English stop words\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "# displaying stopwords\n",
        "np.array(stop_words)"
      ],
      "metadata": {
        "id": "uzv4JHtMpdqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stopwords(text):\n",
        "    '''a function for removing the stopword and lowercase the each word'''\n",
        "    text = [word.lower() for word in text.split() if word.lower() not in stop_words]\n",
        "    # joining the list of words with space separator\n",
        "    return \" \".join(text)\n"
      ],
      "metadata": {
        "id": "slIZh-TbqCQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# applying stopwords function.\n",
        "df['tags'] = df['tags'].apply(stopwords)"
      ],
      "metadata": {
        "id": "Xg7eGAvyqtvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tags[0]"
      ],
      "metadata": {
        "id": "EfZZ49IDqxsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have successfully removed all the stopwords and converted the corpus to lowercase."
      ],
      "metadata": {
        "id": "Gx9dAEWCq6sM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removing Punctuations**"
      ],
      "metadata": {
        "id": "73a766Yvq-3m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing punctuation is a common pre-processing step in natural language processing (NLP) tasks. Punctuation marks like periods, commas, and exclamation points can add noise to the data and can sometimes be treated as separate tokens, which can affect the performance of NLP models."
      ],
      "metadata": {
        "id": "ZrPkSaYxrGKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to remove punctuations\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    '''a function for removing punctuation'''\n",
        "    import string\n",
        "    # replacing the punctuations with no space, which in effect deletes the punctuation marks.\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    # return the text stripped of punctuation marks\n",
        "    return text.translate(translator)\n",
        "     "
      ],
      "metadata": {
        "id": "B7HYHGVprK0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# applying remove_punctuation function\n",
        "df['tags'] = df['tags'].apply(remove_punctuation)"
      ],
      "metadata": {
        "id": "3hlK63wZrO9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tags[0]"
      ],
      "metadata": {
        "id": "OiotX88LrX2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have successfully remove all the punctuation marks from the corpus."
      ],
      "metadata": {
        "id": "4ILHvgJmrlup"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stemming**"
      ],
      "metadata": {
        "id": "wQQxRBLTrtiF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used SnowballStemmer to generate a meaningful word out of corpus of words.\n",
        "\n",
        "Stemming is the process of reducing a word to its base or root form. This is a common pre-processing step in natural language processing (NLP) tasks, as it allows you to treat different inflected forms of a word as the same word, which can be useful for tasks like information retrieval or text classification.\n",
        "\n",
        "For example, the words \"run,\" \"runs,\" \"ran,\" and \"running\" are all different inflected forms of the same word \"run,\" and a stemmer can reduce them all to the base form \"run.\""
      ],
      "metadata": {
        "id": "B3DRjKtnr2su"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "# create an object of stemming function\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "def stemming(text):    \n",
        "    '''a function which stems each word in the given text'''\n",
        "    text = [stemmer.stem(word) for word in text.split()]\n",
        "    return \" \".join(text)"
      ],
      "metadata": {
        "id": "s3rzPgMCr7gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# appying stemming function\n",
        "df['tags'] = df['tags'].apply(stemming)"
      ],
      "metadata": {
        "id": "042TCmx3r9s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tags[0]"
      ],
      "metadata": {
        "id": "IZTbeHUnsDXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have stemming the corpus."
      ],
      "metadata": {
        "id": "IPZJ9cBXsMAn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Vectorization**\n",
        "\n",
        "Word/Text vectorization is the process of representing words as numerical vectors. This is important in NLP tasks because most machine learning models expect numerical input and cannot work with raw text data directly. Word vectorization allows you to input the words into a machine learning model in a way that preserve the meaning and context of the words. Word vectorization can also be used to measure the similarity between words using vector arithmetic."
      ],
      "metadata": {
        "id": "9GhLsoKjsY3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the object of tfid vectorizer\n",
        "tfidf = TfidfVectorizer(stop_words='english', lowercase=False, max_features = 10000)   # max features = 10000 to prevent system from crashing\n",
        "\n",
        "# fit the vectorizer using the text data\n",
        "tfidf.fit(df['tags'])\n",
        "\n",
        "# collect the vocabulary items used in the vectorizer\n",
        "dictionary = tfidf.vocabulary_.items()"
      ],
      "metadata": {
        "id": "8wA3t0E-sN5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dictionary)) #number of independet features created from \"tags\" columns ---> max_features=10000"
      ],
      "metadata": {
        "id": "PTOnWvjKsuOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert vector into array form for clustering\n",
        "vector = tfidf.transform(df['tags']).toarray()\n",
        "\n",
        "# summarize encoded vector\n",
        "print(vector)\n",
        "print(f'shape of the vector : {vector.shape}')\n",
        "print(f'datatype : {type(vector)}')"
      ],
      "metadata": {
        "id": "_NlRNhZZszca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dimesionality Reduction**"
      ],
      "metadata": {
        "id": "IZh8ONV1s7aL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use PCA (Principal component Analysis) to reduce the dimensionality of data.\n",
        "\n",
        "Dimensionality reduction is the process of reducing the number of features or dimensions in a dataset while preserving as much information as possible. It is a common step in machine learning and data analysis, as high-dimensional datasets can be difficult to work with and can sometimes suffer from the curse of dimensionality."
      ],
      "metadata": {
        "id": "6j_XBgsctFqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using PCA to reduce dimensionality\n",
        "pca = PCA(random_state=42)\n",
        "pca.fit(vector)"
      ],
      "metadata": {
        "id": "FlBm4ANntJu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explained variance for different number of components\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.title('PCA - cumulative explained variance vs number of components')\n",
        "plt.xlabel('number of components')\n",
        "plt.ylabel('cumulative explained variance')\n",
        "plt.axhline(y= 0.8, color='red', linestyle='--')\n",
        "plt.axvline(x= 3000, color='green', linestyle='--')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EuQFbGITtPoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We find that 100% of the variance is explained by about ~7500 components.\n",
        "\n",
        "Also, more than 80% of the variance is explained just by 3000 components.\n",
        "\n",
        "Hence to simplify the model, and reduce dimensionality, we can take the top \n",
        "\n",
        "3000 components, which will still be able to capture more than 80% of variance."
      ],
      "metadata": {
        "id": "0b5fSEMbuq1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reducing the dimensions to 3000 using pca\n",
        "pca = PCA(n_components=3000, random_state=42)\n",
        "pca.fit(vector)"
      ],
      "metadata": {
        "id": "ZRhu-oeiu0LF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformed features\n",
        "X = pca.transform(vector)\n",
        "\n",
        "# shape of transformed vectors\n",
        "X.shape"
      ],
      "metadata": {
        "id": "Vw49YF-Ou8s_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Clusters implementation**"
      ],
      "metadata": {
        "id": "dpxl0BibvyXO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.**K-Means Clustering**\n",
        "\n",
        "K-means clustering is an unsupervised machine learning algorithm that is used to divide a dataset into a specified number of clusters. It is called \"unsupervised\" because the algorithm does not use any labeled examples to learn about the data. Instead, it relies on the inherent structure of the data to group the samples into clusters.\n",
        "\n",
        "How It's Work?\n",
        "\n",
        "The k-means algorithm works by first selecting k initial \"centroids,\" or cluster centers, at random from the data.\n",
        "Then, it assigns each sample in the dataset to the nearest centroid, based on some distance metric like Euclidean distance.\n",
        "The algorithm then updates the centroids to be the mean of the samples in each cluster.\n",
        "teratively repeats the process of reassigning samples to the nearest centroids and updating the centroids until convergence.\n",
        "Visualizing the elbow curve and Silhouette score to decide on the optimal number of clusters for K-means clustering algorithm"
      ],
      "metadata": {
        "id": "KcNmMSCXv8g3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Elbow method to find the optimal value of k'''\n",
        "\n",
        "# Initialize a list to store the sum of squared errors for each value of k\n",
        "SSE = []\n",
        "\n",
        "for k in range(1, 16):\n",
        "  # Initialize the k-means model with the current value of k\n",
        "  kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42)\n",
        "  # Fit the model to the data\n",
        "  kmeans.fit(X)\n",
        "  # Compute the sum of squared errors for the model\n",
        "  SSE.append(kmeans.inertia_)\n",
        "\n",
        "# Plot the values of SSE\n",
        "plt.plot(range(1, 16), SSE)\n",
        "plt.title('The Elbow Method - KMeans clustering')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('Sum of squared errors')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZUy4ysOVv7hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sum of squared distance between each point and the centroid in a cluster decreases with the increase in the number of clusters."
      ],
      "metadata": {
        "id": "7MrKKmTIxIdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Silhouette score method to find the optimal value of k'''\n",
        "\n",
        "# Initialize a list to store the silhouette score for each value of k\n",
        "silhouette_avg = []\n",
        "\n",
        "for k in range(2, 16):\n",
        "  # Initialize the k-means model with the current value of k\n",
        "  kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42)\n",
        "  # Fit the model to the data\n",
        "  kmeans.fit(X)\n",
        "  # Predict the cluster labels for each point in the data\n",
        "  labels = kmeans.labels_\n",
        "  # Compute the silhouette score for the model\n",
        "  score = silhouette_score(X, labels)\n",
        "  silhouette_avg.append(score)\n",
        "  \n",
        "# Plot the Silhouette analysis\n",
        "plt.plot(range(2,16), silhouette_avg)\n",
        "plt.xlabel('Number of clusters') \n",
        "plt.ylabel('Silhouette score')\n",
        "plt.title('Silhouette analysis For Optimal k - KMeans clustering')"
      ],
      "metadata": {
        "id": "CXugGBP9xR5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The highest Silhouette score is obtained for 5 clusters."
      ],
      "metadata": {
        "id": "Kzg7eOztxb38"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building 5 clusters using the k-means clustering algorithm:"
      ],
      "metadata": {
        "id": "JrMoPUVixmjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clustering the data into 5 clusters\n",
        "kmeans = KMeans(n_clusters=5, init='k-means++', random_state=33)\n",
        "kmeans.fit(X)"
      ],
      "metadata": {
        "id": "NAX4BlMGxe25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics - distortion, Silhouette score\n",
        "kmeans_distortion = kmeans.inertia_\n",
        "kmeans_silhouette_score = silhouette_score(X, kmeans.labels_)\n",
        "\n",
        "print((kmeans_distortion, kmeans_silhouette_score))"
      ],
      "metadata": {
        "id": "Hkvnw_UAxzUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a kmeans cluster number attribute\n",
        "df['kmeans_cluster'] = kmeans.labels_"
      ],
      "metadata": {
        "id": "b1ytKf3Ex6rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(5)[['type', 'title', 'director', 'cast', 'country', 'rating', 'listed_in', 'description', 'kmeans_cluster']]"
      ],
      "metadata": {
        "id": "DN3urIVwyGnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of movies and tv shows in each cluster\n",
        "plt.figure(figsize=(8,5))\n",
        "graph = sns.countplot(x='kmeans_cluster',data=df, hue='type')\n",
        "plt.title('Number of movies and TV shows in each cluster - Kmeans Clustering')\n",
        "\n",
        "# adding value count on the top of bar\n",
        "for p in graph.patches:\n",
        "   graph.annotate(format(p.get_height(), '.0f'), (p.get_x(), p.get_height()))"
      ],
      "metadata": {
        "id": "c8fKY6i1yP6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Successfully built 5 clusters using the k-means clustering algorithm."
      ],
      "metadata": {
        "id": "dxh65kOtyWEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building wordclouds for different clusters in K-Means Clustering**"
      ],
      "metadata": {
        "id": "R94thfg1yXiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kmeans_worldcloud(cluster_number, column_name):\n",
        "  \n",
        "  '''function for Building a wordcloud for the movie/shows'''\n",
        "\n",
        "  df_wordcloud = df[['kmeans_cluster',column_name]].dropna()\n",
        "  df_wordcloud = df_wordcloud[df_wordcloud['kmeans_cluster']==cluster_number]\n",
        "  \n",
        "  # text documents\n",
        "  text = \" \".join(word for word in df_wordcloud[column_name])\n",
        "\n",
        "  # create the word cloud\n",
        "  wordcloud = WordCloud(stopwords=set(STOPWORDS), background_color=\"white\").generate(text)\n",
        "  \n",
        "  # Generate a word cloud image\n",
        "  plt.imshow(wordcloud, interpolation='bilinear')\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "77xvjoWAyf2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word Cloud on \"description\" column for different cluster**"
      ],
      "metadata": {
        "id": "Vl9gsYziyofr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(f'cluster {i}')\n",
        "  kmeans_worldcloud(i,'description')"
      ],
      "metadata": {
        "id": "gvI7ElpSyrez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(f'cluster {i}')\n",
        "  kmeans_worldcloud(i,'cast')"
      ],
      "metadata": {
        "id": "BdCZXIm7y5MJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(f'cluster {i}')\n",
        "  kmeans_worldcloud(i,'director')"
      ],
      "metadata": {
        "id": "vRu3Sli8y-Sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(f'cluster {i}')\n",
        "  kmeans_worldcloud(i,'listed_in')"
      ],
      "metadata": {
        "id": "aZVhslx7zCI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(f'cluster {i}')\n",
        "  kmeans_worldcloud(i,'country')"
      ],
      "metadata": {
        "id": "Eov5R1yVzHS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(f'cluster {i}')\n",
        "  kmeans_worldcloud(i,'title')"
      ],
      "metadata": {
        "id": "9l_dZ6yRzLwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2.Hierarchical clustering**"
      ],
      "metadata": {
        "id": "dtbZkRTQzqrp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After applying the agglomerative hierarchical clustering algorithm, the resulting clusters are displayed in a dendrogram, which is a tree-like structure. The dendrogram shows the relationships between the clusters at each level of the hierarchy.\n",
        "\n",
        "To determine the optimal number of clusters for our data, we can visually inspect the dendrogram and look for the largest vertical distance that does not intersect any horizontal line. This distance represents the largest distance between any two merged clusters, and thus the point at which the clusters are most dissimilar.\n",
        "\n",
        "We can then draw a horizontal line at this distance and count the number of vertical lines it intersects. This number corresponds to the optimal number of clusters for our data."
      ],
      "metadata": {
        "id": "ZbYI0Bl_0Jxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a dendogram to decide the number of clusters\n",
        "plt.figure(figsize=(10, 7))  \n",
        "dend = shc.dendrogram(shc.linkage(X, method='ward'))\n",
        "plt.title('Dendrogram')\n",
        "plt.xlabel('Netflix Shows')\n",
        "plt.ylabel('Distance')\n",
        "plt.axhline(y= 4, color='r', linestyle='--')\n",
        "     "
      ],
      "metadata": {
        "id": "BULYx8GizxRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**At a distance of 4 units, 7 clusters can be built using the agglomerative clustering algorithm.**"
      ],
      "metadata": {
        "id": "VduutNQN0V7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building 7 clusters using the Agglomerative clustering algorithm:"
      ],
      "metadata": {
        "id": "kIue8a9t0bj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting hierarchical clustering model\n",
        "hierarchical = AgglomerativeClustering(n_clusters=7, affinity='euclidean', linkage='ward')  \n",
        "hierarchical.fit_predict(X)\n",
        "     "
      ],
      "metadata": {
        "id": "PNR3b1xR0em1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a hierarchical cluster number attribute\n",
        "df['hierarchical_cluster'] = hierarchical.labels_\n",
        "     "
      ],
      "metadata": {
        "id": "Ib0OrV6b0i_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(5)[['type', 'title', 'director', 'cast', 'country', 'rating', 'listed_in', 'description', 'hierarchical_cluster']]"
      ],
      "metadata": {
        "id": "82YtODU60kMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of movies and tv shows in each cluster\n",
        "plt.figure(figsize=(10,5))\n",
        "graph = sns.countplot(x='hierarchical_cluster',data=df, hue='type')\n",
        "plt.title('Number of movies and tv shows in each cluster - Hierarchical Clustering')\n",
        "\n",
        "# adding value count on the top of bar\n",
        "for p in graph.patches:\n",
        "   graph.annotate(format(p.get_height(), '.0f'), (p.get_x(), p.get_height()))"
      ],
      "metadata": {
        "id": "MzHPIssd0n_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Successfully built 7 clusters using the Agglomerative (hierarchical) clustering algorithm."
      ],
      "metadata": {
        "id": "X9Tr38nu0vUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building wordclouds for different clusters in hierarchical Clustering**"
      ],
      "metadata": {
        "id": "-Q9KUL8E03ED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hierarchical_worldcloud(cluster_number, column_name):\n",
        "  \n",
        "  '''function for Building a wordcloud for the movie/shows'''\n",
        "\n",
        "  df_wordcloud = df[['hierarchical_cluster',column_name]].dropna()\n",
        "  df_wordcloud = df_wordcloud[df_wordcloud['hierarchical_cluster']==cluster_number]\n",
        "  \n",
        "  # text documents\n",
        "  text = \" \".join(word for word in df_wordcloud[column_name])\n",
        "\n",
        "  # create the word cloud\n",
        "  wordcloud = WordCloud(stopwords=set(STOPWORDS), background_color=\"white\").generate(text)\n",
        "  \n",
        "  # Generate a word cloud image\n",
        "  plt.imshow(wordcloud, interpolation='bilinear')\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "fKGSx0-h09Hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word Cloud on \"title\" column for different cluster**"
      ],
      "metadata": {
        "id": "FNT4oLfo1Biy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(7):\n",
        "  print(f'cluster {i}')\n",
        "  hierarchical_worldcloud(i,'title')"
      ],
      "metadata": {
        "id": "092hG3Qk1II2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word Cloud on \"description\" column for different cluster**"
      ],
      "metadata": {
        "id": "J1IUaxl31NT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(7):\n",
        "  print(f'cluster {i}')\n",
        "  hierarchical_worldcloud(i,'description')"
      ],
      "metadata": {
        "id": "h121gdhy1Qwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word Cloud on \"cast\" column for different cluster**"
      ],
      "metadata": {
        "id": "SnKQiFGR1XzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(7):\n",
        "  print(f'cluster {i}')\n",
        "  hierarchical_worldcloud(i,'cast')"
      ],
      "metadata": {
        "id": "j3bDi3vK12LS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word Cloud on \"country\" column for different cluster**"
      ],
      "metadata": {
        "id": "rNVk8aug16E_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(7):\n",
        "  print(f'cluster {i}')\n",
        "  hierarchical_worldcloud(i,'country')"
      ],
      "metadata": {
        "id": "UD-Pv2b919Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word Cloud on \"listed_in (genre)\" column for different cluster**"
      ],
      "metadata": {
        "id": "Uvp1friM2Ku1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(7):\n",
        "  print(f'cluster {i}')\n",
        "  hierarchical_worldcloud(i,'listed_in')"
      ],
      "metadata": {
        "id": "RjNv4SRf2R-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Content Based Recommendation System**\n",
        "\n",
        "Content-based recommendation systems recommend items to a user by using the similarity of items. This recommender system recommends products or items based on their description or features. It identifies the similarity between the products based on their descriptions.\n",
        "\n",
        "It short notes which items a particular user likes and also the items that the users with behavior and likings like him/her likes, to recommend items to that user.\n",
        "\n",
        "We can build a simple content based recommender system based on the similarity of the movie/shows.\n",
        "If a person has watched a show on Netflix, the recommender system must be able to recommend a list of similar shows that s/he likes.\n",
        "To get the similarity score of the shows, we can use cosine similarity.\n",
        "The similarity between two vectors (A and B) is calculated by taking the dot product of the two vectors and dividing it by the magnitude value. We can simply say that the cosine similarity score of two vectors increases as the angle between them decreases."
      ],
      "metadata": {
        "id": "KXBBpNtx2WS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# veryfying index\n",
        "df[['show_id', 'title', 'tags']]"
      ],
      "metadata": {
        "id": "RRznAHNz2fcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.The dataframe under consideration has a total of 7770 rows. However, due to the removal of some rows containing null values, the last index shown in the dataframe is 7786.\n",
        "\n",
        "2.To build a content-based recommendation system, we calculate the similarity score based on a specific index_id with respect to the corresponding \"tags\" column.\n",
        "\n",
        "3.Failure to reset the index may result in the calculation of cosine similarity for a different index, leading to incorrect recommendations. Hence, resetting the index is essential to ensure that the recommendations are based on the correct index.\n",
        "\n",
        "4.Resetting the index involves assigning a new sequential index to each row of the dataframe, starting from 0. This ensures that each row has a unique and identifiable index, making it easier to perform computations and obtain accurate results.\n",
        "\n",
        "5.Therefore, resetting the index is a crucial step in building a content-based recommendation system, as it ensures that the recommendations are based on the correct index and leads to more accurate and relevant recommendations."
      ],
      "metadata": {
        "id": "cvlFZu-Z2zes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining new dataframe for building recommandation system\n",
        "recommender_df = df.copy()\n",
        "\n",
        "# reseting index\n",
        "recommender_df.reset_index(inplace=True)\n",
        "\n",
        "# checking whether or not reset index properly \n",
        "recommender_df[['show_id', 'title', 'tags']]"
      ],
      "metadata": {
        "id": "q6_cFUZI3Bi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see above dataframe We successfully reset the index. Now dataset is ready to build content based recommandation system"
      ],
      "metadata": {
        "id": "kfBjiAcY3Jz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping show-id and index column\n",
        "recommender_df.drop(columns=['index', 'show_id'], inplace=True)"
      ],
      "metadata": {
        "id": "lbPVM7DN3K40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"before reset index id for movie 'Zero' : {df[df['title'] == 'Zero'].index[0]}\")  # index[0] --> to locate index position\n",
        "print(f\"after reset index id for movie 'Zero': {recommender_df[recommender_df['title'] == 'Zero'].index[0]}\")"
      ],
      "metadata": {
        "id": "GdJqrM7l3TYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calling out transformed array independent features created from tags(cluster) column after performing PCA for dimenssionality reduction.\n",
        "X"
      ],
      "metadata": {
        "id": "86Moux-e3YIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate cosine similarity\n",
        "similarity = cosine_similarity(X)\n",
        "similarity"
      ],
      "metadata": {
        "id": "Dr8HHqfZ3hNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function for list down top 10 recommended movie on the basis of cosine similarity score.**"
      ],
      "metadata": {
        "id": "FgK0gsur3obi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend(movie):\n",
        "    '''\n",
        "    This function list down top ten movies on the basis of similarity score for that perticular movie.\n",
        "    '''\n",
        "    print(f\"If you liked '{movie}', you may also enjoy: \\n\")\n",
        "\n",
        "    # find out index position\n",
        "    index = recommender_df[recommender_df['title'] == movie].index[0]\n",
        "\n",
        "    # sorting on the basis of simliarity score, In order to find out distaces from recommended one\n",
        "    distances = sorted(list(enumerate(similarity[index])), reverse=True, key=lambda x:x[1])\n",
        "    \n",
        "    # listing top ten recommenaded movie\n",
        "    for i in distances[1:11]:\n",
        "        print(df.iloc[i[0]].title)"
      ],
      "metadata": {
        "id": "hAd89u2b3wEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend('Naruto')"
      ],
      "metadata": {
        "id": "fjmLfVs04LK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend('Our Planet')"
      ],
      "metadata": {
        "id": "UHS1JxN84ToJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend('Phir Hera Pheri')"
      ],
      "metadata": {
        "id": "MxD1ZX-34YZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Welcome to our exciting journey of exploring the world of Netflix shows! Our goal was to cluster the shows into groups based on their similarities and differences, ultimately creating a content-based recommender system that suggests 10 shows based on the user's viewing history.\n",
        "\n",
        "With over 7787 records and 11 attributes, we began our adventure by delving into the dataset's missing values and performing exploratory data analysis (EDA). Our findings revealed that Netflix boasts more movies than TV shows, with a rapidly growing collection of shows from the United States.\n",
        "\n",
        "To cluster the shows, we focused on six key attributes: director, cast, country, genre, rating, and description. We transformed these attributes into a 10000-feature TFIDF vectorization, then used Principal Component Analysis (PCA) to tackle the curse of dimensionality. By reducing the components to 3000, we were able to capture more than 80% of the variance.\n",
        "\n",
        "Next, we used two clustering algorithms, K-Means and Agglomerative clustering, to group the shows. K-Means determined that the optimal number of clusters was 5, as confirmed by the elbow method and Silhouette score analysis. Meanwhile, Agglomerative clustering suggested 7 clusters, which we visualized using a dendrogram.\n",
        "\n",
        "But we didn't stop there. We then created a content-based recommender system using the similarity matrix obtained through cosine similarity. This system provides personalized recommendations based on the type of show the user has watched, giving them 10 top-notch suggestions to explore.\n",
        "\n",
        "Join us in discovering the diverse world of Netflix shows, and let our recommender system guide you to your next binge-worthy obsession."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}